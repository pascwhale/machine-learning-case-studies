{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Diabetic Retinopathy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Description"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Diabetic Retinopathy (DR) dataset predicts whether an image contains signs of diabetic retinopathy. The dataset contains features that have been extracted frm the [Messidor](https://www.adcis.net/en/third-party/messidor/) image set.\r\n",
    "\r\n",
    "The column attributes are as follows:\r\n",
    "\r\n",
    "| Column Name | Description |\r\n",
    "| - | - |\r\n",
    "| assessment_quality | Quality of assessment |\r\n",
    "| prescreening_result | Pre-screening analysis results |\r\n",
    "| mas_alpha_5 | Number of microaneurysms (MA) detected at confidence level alpha=0.5 |\r\n",
    "| mas_alpha_6 | Number of microaneurysms (MA) detected at confidence level alpha=0.6 |\r\n",
    "| mas_alpha_7 | Number of microaneurysms (MA) detected at confidence level alpha=0.7 |\r\n",
    "| mas_alpha_8 | Number of microaneurysms (MA) detected at confidence level alpha=0.8 |\r\n",
    "| mas_alpha_9 | Number of microaneurysms (MA) detected at confidence level alpha=0.9 |\r\n",
    "| mas_alpha_10 | Number of microaneurysms (MA) detected at confidence level alpha=1.0 |\r\n",
    "| exudates_alpha_50 | Number of exudates found at confidence level alpha=0.50 divided by the diameter of the region of interest (ROI) |\r\n",
    "| exudates_alpha_57 | Number of exudates found at confidence level alpha≈0.57 divided by the diameter of the region of interest (ROI) |\r\n",
    "| exudates_alpha_64 | Number of exudates found at confidence level alpha≈0.64 divided by the diameter of the region of interest (ROI) |\r\n",
    "| exudates_alpha_71 | Number of exudates found at confidence level alpha≈0.71 divided by the diameter of the region of interest (ROI) |\r\n",
    "| exudates_alpha_79 | Number of exudates found at confidence level alpha≈0.79 divided by the diameter of the region of interest (ROI) |\r\n",
    "| exudates_alpha_86 | Number of exudates found at confidence level alpha≈0.86 divided by the diameter of the region of interest (ROI) |\r\n",
    "| exudates_alpha_93 | Number of exudates found at confidence level alpha≈0.93 divided by the diameter of the region of interest (ROI) |\r\n",
    "| exudates_alpha_100 | Number of exudates found at confidence level alpha=1.00 divided by the diameter of the region of interest (ROI) |\r\n",
    "| macula_disc_distance | Euclidean distance of the center of the macula and the center of the optic disct divided by the diameter of the region of  |interest (ROI)\r\n",
    "| disc_diameter | Diameter of the optic disc |\r\n",
    "| am_fm_result | Binary result from AM/FM-based classification |\r\n",
    "| contains_DR | Class label 0 (no signs of diabetic retinopathy) and 1 (contains signs of diabetic retinopathy) |\r\n",
    "\r\n",
    "[Source](https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "from scipy.io import arff\r\n",
    "\r\n",
    "column_names = ['assessment_quality',\r\n",
    "                'prescreening_result',\r\n",
    "                'mas_alpha_5',\r\n",
    "                'mas_alpha_6',\r\n",
    "                'mas_alpha_7',\r\n",
    "                'mas_alpha_8',\r\n",
    "                'mas_alpha_9',\r\n",
    "                'mas_alpha_10',\r\n",
    "                'exudates_alpha_50',\r\n",
    "                'exudates_alpha_57',\r\n",
    "                'exudates_alpha_64',\r\n",
    "                'exudates_alpha_71',\r\n",
    "                'exudates_alpha_79',\r\n",
    "                'exudates_alpha_86',\r\n",
    "                'exudates_alpha_93',\r\n",
    "                'exudates_alpha_100',\r\n",
    "                'macula_disc_distance',\r\n",
    "                'disc_diameter',\r\n",
    "                'am_fm_result',\r\n",
    "                'contains_DR']\r\n",
    "features = column_names[:-1]\r\n",
    "target = column_names[-1]\r\n",
    "\r\n",
    "with open(\"../../datasets/classification/diabetic_retinopathy.arff\", \"r\") as dataset_file:\r\n",
    "    raw_data, meta = arff.loadarff(dataset_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert the raw numpy dataset to a pandas DataFrame. This allows for mixed datatypes within the same multidimensional matrix object.\r\n",
    "prepared_data = pd.DataFrame(raw_data.tolist(), columns=column_names)\r\n",
    "\r\n",
    "# Decode integer columns.\r\n",
    "prepared_data['assessment_quality'] = prepared_data['assessment_quality'].astype(int)\r\n",
    "prepared_data['prescreening_result'] = prepared_data['prescreening_result'].astype(int)\r\n",
    "prepared_data['mas_alpha_5'] = prepared_data['mas_alpha_5'].astype(int)\r\n",
    "prepared_data['mas_alpha_6'] = prepared_data['mas_alpha_6'].astype(int)\r\n",
    "prepared_data['mas_alpha_7'] = prepared_data['mas_alpha_7'].astype(int)\r\n",
    "prepared_data['mas_alpha_8'] = prepared_data['mas_alpha_8'].astype(int)\r\n",
    "prepared_data['mas_alpha_9'] = prepared_data['mas_alpha_9'].astype(int)\r\n",
    "prepared_data['mas_alpha_10'] = prepared_data['mas_alpha_10'].astype(int)\r\n",
    "prepared_data['am_fm_result'] = prepared_data['am_fm_result'].astype(int)\r\n",
    "\r\n",
    "# Decode integer target column.\r\n",
    "prepared_data['contains_DR'] = prepared_data['contains_DR'].astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following block prints the shape and column datatypes of the processed dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(prepared_data.shape)\r\n",
    "print(prepared_data.dtypes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_full = prepared_data[features].copy()\r\n",
    "y_full = prepared_data[target].copy()\r\n",
    "\r\n",
    "# Split the dataset into two parts, one part training, the other, testing and validating.\r\n",
    "X_train, X_test_and_val, y_train, y_test_and_val = train_test_split(X_full, y_full, \r\n",
    "                                                        train_size=0.6,\r\n",
    "                                                        random_state=0)\r\n",
    "# Split the second part from the previous split into two parts, one part testing, the other, validating.\r\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_and_val, y_test_and_val, \r\n",
    "                                                        train_size=0.5,\r\n",
    "                                                        random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler = StandardScaler()\r\n",
    "# Fit scaler to data then transform it.\r\n",
    "X_train_scaled = scaler.fit_transform(X_train)\r\n",
    "\r\n",
    "# Apply same transformation to test and validation data without fitting.\r\n",
    "X_test_scaled = scaler.transform(X_test)\r\n",
    "X_val_scaled = scaler.transform(X_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training on Multiple Classifiers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Manage imports\r\n",
    "import sklearn.linear_model\r\n",
    "import sklearn.tree\r\n",
    "import sklearn.ensemble\r\n",
    "import sklearn.neighbors\r\n",
    "import sklearn.naive_bayes\r\n",
    "from utilities import train_estimators, plot_estimator_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adjusted_parameter = 'C'\r\n",
    "adjusted_parameter_values = [1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0]\r\n",
    "\r\n",
    "LogisticRegressionEstimators = train_estimators(X_train_scaled, y_train,\r\n",
    "                                                sklearn.linear_model.LogisticRegression,\r\n",
    "                                                adjusted_parameter, adjusted_parameter_values,\r\n",
    "                                                max_iter=10000,\r\n",
    "                                                random_state=0)\r\n",
    "plot_estimator_scores(LogisticRegressionEstimators,\r\n",
    "                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                        X_train_scaled, y_train, X_test_scaled, y_test, X_val_scaled, y_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adjusted_parameter = 'C'\r\n",
    "adjusted_parameter_values = [0.01, 0.1,1.0,10.0,100.0]\r\n",
    "\r\n",
    "SVMEstimators = train_estimators(X_train_scaled, y_train,\r\n",
    "                                    sklearn.svm.SVC,\r\n",
    "                                    adjusted_parameter, adjusted_parameter_values,\r\n",
    "                                    gamma=0.0001,\r\n",
    "                                    max_iter=10000,\r\n",
    "                                    random_state=0)\r\n",
    "plot_estimator_scores(SVMEstimators,\r\n",
    "                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                        X_train_scaled, y_train, X_test_scaled, y_test, X_val_scaled, y_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adjusted_parameter = 'max_depth'\r\n",
    "adjusted_parameter_values = [1, 5, 10, 20, 50, 100]\r\n",
    "\r\n",
    "DecisionTreeEstimators = train_estimators(X_train_scaled, y_train,\r\n",
    "                                            sklearn.tree.DecisionTreeClassifier,\r\n",
    "                                            adjusted_parameter, adjusted_parameter_values,\r\n",
    "                                            splitter='random',\r\n",
    "                                            random_state=0)\r\n",
    "plot_estimator_scores(DecisionTreeEstimators,\r\n",
    "                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                        X_train_scaled, y_train, X_test_scaled, y_test, X_val_scaled, y_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adjusted_parameter = 'max_depth'\r\n",
    "adjusted_parameter_values = [1, 5, 10, 20, 50, 100]\r\n",
    "\r\n",
    "RandomTreeEstimators = train_estimators(X_train_scaled, y_train,\r\n",
    "                                        sklearn.ensemble.RandomForestClassifier,\r\n",
    "                                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                                        random_state=0)\r\n",
    "plot_estimator_scores(RandomTreeEstimators,\r\n",
    "                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                        X_train_scaled, y_train, X_test_scaled, y_test, X_val_scaled, y_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-Nearest Neighbours Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adjusted_parameter = 'weights'\r\n",
    "adjusted_parameter_values = ['uniform','distance']\r\n",
    "\r\n",
    "KNearestEstimators = train_estimators(X_train_scaled, y_train,\r\n",
    "                                        sklearn.neighbors.KNeighborsClassifier,\r\n",
    "                                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                                        n_neighbors=2)\r\n",
    "plot_estimator_scores(KNearestEstimators,\r\n",
    "                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                        X_train_scaled, y_train, X_test_scaled, y_test, X_val_scaled, y_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adjusted_parameter = 'algorithm'\r\n",
    "adjusted_parameter_values = ['auto', 'ball_tree', 'kd_tree','brute']\r\n",
    "\r\n",
    "KNearestEstimators = train_estimators(X_train_scaled, y_train,\r\n",
    "                                        sklearn.neighbors.KNeighborsClassifier,\r\n",
    "                                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                                        n_neighbors=2)\r\n",
    "plot_estimator_scores(KNearestEstimators,\r\n",
    "                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                        X_train_scaled, y_train, X_test_scaled, y_test, X_val_scaled, y_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ada Boost Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adjusted_parameter = 'n_estimators'\r\n",
    "adjusted_parameter_values = [10, 50, 100, 500, 1000, 5000]\r\n",
    "\r\n",
    "AdaBoostEstimators = train_estimators(X_train_scaled, y_train,\r\n",
    "                                        sklearn.ensemble.AdaBoostClassifier,\r\n",
    "                                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                                        random_state=0)\r\n",
    "plot_estimator_scores(AdaBoostEstimators,\r\n",
    "                        adjusted_parameter, adjusted_parameter_values,\r\n",
    "                        X_train_scaled, y_train, X_test_scaled, y_test, X_val_scaled, y_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Naive Bayes Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gaussian_nb = sklearn.naive_bayes.GaussianNB()\r\n",
    "NaiveBayesEstimator = gaussian_nb.fit(X_train, y_train)\r\n",
    "gaussian_nb_train_score = NaiveBayesEstimator.score(X_train, y_train)\r\n",
    "gaussian_nb_test_score =  NaiveBayesEstimator.score(X_test, y_test)\r\n",
    "gaussian_nb_val_score =  NaiveBayesEstimator.score(X_val, y_val)\r\n",
    "print(f'{gaussian_nb_train_score=}, {gaussian_nb_val_score=}, {gaussian_nb_test_score=}')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('comp432': conda)"
  },
  "interpreter": {
   "hash": "6151f332f26dcde9b4e9a2d5bb7904271ea54c2018786e9b563d2c471a54dc4f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Data Set (Red/White) \n",
    "## Description\n",
    "\n",
    "Data set of wines samples containing their attributes such as acidity, chlorides, density, etc. These wines were documented and then scored by professional wine testers.\n",
    "\n",
    "The column attributes are as follows:\n",
    "\n",
    "| Id | Attribute |Domain |\n",
    "| -   | ----------- |----------- |\n",
    "| 1   | fixed acidity | 0 - 10   |\n",
    "| 2   | volatile acidity   | 0 - 1 |\n",
    "| 3   | citric acid | 0 - 100 | \n",
    "| 4   |residual sugar | 0 - 0.1 |\n",
    "| 5   | chlorides | 0 - 1 |\n",
    "| 6   | free sulfur dioxide| 0 or 0.5 |\n",
    "| 7   | total sulfur dioxide   |0 - 1 |\n",
    "| 8   |  density| 0 - 1 |\n",
    "| 9   |pH| 0 - 1 |\n",
    "| 10  | sulphates | Location ID |\n",
    "| 11  | alcohol | Location ID |\n",
    "| 12  | quality | Location ID |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                        # for os.path.exists\n",
    "import json                      # for loading metadata\n",
    "import urllib                    # for downloading remote files \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(remoteurl: str, localfile: str):\n",
    "    \"\"\"\n",
    "    Download remoteurl to localfile, unless localfile already exists.\n",
    "    Returns the localfile string.\n",
    "    \"\"\"\n",
    "    localfile = \"../../datasets/classification/\"+localfile\n",
    "    if not os.path.exists(localfile):\n",
    "        print(\"Downloading %s...\" % localfile)\n",
    "        filename, headers = urllib.request.urlretrieve(remoteurl, localfile)\n",
    "    return localfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../../datasets/classification/wine-data-red...\n"
     ]
    }
   ],
   "source": [
    "wine_data_red= download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\"wine-data-red\")\n",
    "headers = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
    "data_red = pd.read_csv(wine_data_red, header = None, names = headers, sep = ';')\n",
    "data_red  = data_red.iloc[1: , :]\n",
    "\n",
    "for x in data_red:\n",
    "    data_red[x] = pd.to_numeric(data_red[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_red = data_red.drop(columns = [\"pH\"])\n",
    "data_red.shape\n",
    "# data_red = data_red.filter(['sulphates','density','total sulfur dioxide','chlorides','volatile acidity','alcohol','quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1            7.4              0.70         0.00             1.9      0.076   \n",
       "2            7.8              0.88         0.00             2.6      0.098   \n",
       "3            7.8              0.76         0.04             2.3      0.092   \n",
       "4           11.2              0.28         0.56             1.9      0.075   \n",
       "5            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "2                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "3                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "4                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "5                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "1      9.4        5  \n",
       "2      9.8        5  \n",
       "3      9.8        5  \n",
       "4      9.8        6  \n",
       "5      9.4        5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = (data_red.iloc[:,:data_red.shape[1]-1]).to_numpy().flatten().reshape(data_red.shape[0],-1)\n",
    "X = (data_red.iloc[:,:data_red.shape[1]-1]).to_numpy().flatten().reshape(data_red.shape[0],-1)\n",
    "y = data_red.iloc[:,data_red.shape[1]-1:data_red.shape[1]].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training and plotting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_estimators(X, y, estimator_type, param_name, param_vals, **kwargs):\n",
    "    \"\"\"\n",
    "    \n",
    "    Trains multiple instances of `estimator_type` on (X, y) by setting argument\n",
    "    named `param_name` to each value in `param_vals`. Prints a message before\n",
    "    training each instance. Returns the list of trained estimators.\n",
    "    \n",
    "    For example:\n",
    "    \n",
    "       >>> train_estimators(X, y, DecisionTreeClassifier, 'max_depth', [1, 5, 10],\n",
    "                            splitter='random', random_state=0)\n",
    "    \n",
    "       Training DecisionTreeClassifier(max_depth=1, random_state=0, splitter='random')...\n",
    "       Training DecisionTreeClassifier(max_depth=5, random_state=0, splitter='random')...\n",
    "       Training DecisionTreeClassifier(max_depth=10, random_state=0, splitter='random')...\n",
    "\n",
    "       [DecisionTreeClassifier(max_depth=1, random_state=0, splitter='random'),\n",
    "        DecisionTreeClassifier(max_depth=5, random_state=0, splitter='random'),\n",
    "        DecisionTreeClassifier(max_depth=10, random_state=0, splitter='random')] \n",
    "    \"\"\"\n",
    "    # Your implementation here. Aim for 5-10 lines.\n",
    "    estimators = []\n",
    "    extra_params = ''\n",
    "\n",
    "    for arg in kwargs:\n",
    "        extra_params = extra_params + str(arg) + '=' + str(kwargs[arg])+ ', ' \n",
    "        \n",
    "    for val in param_vals:\n",
    "        estimator = estimator_type(**{param_name : val}, **kwargs).fit(X,y)\n",
    "        estimators.append(estimator)\n",
    "        print('Training' + ' ' +str(estimator.__class__.__name__) +'(' + str(param_name) + '=' + str(val) + ', ' + extra_params + ')...')\n",
    "\n",
    "    return estimators;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_estimator_scores(estimators, param_name, param_vals):\n",
    "    \"\"\"\n",
    "    Plots the training, validation, and testing scores of a list of estimators,\n",
    "    where `param_name` and `param_vals` are the same as for `train_estimators`.\n",
    "    The estimator with best validation score will be highlighted with an 'x'.\n",
    "    \"\"\"\n",
    "    # Your implementation here. Use as many lines as you need.\n",
    "\n",
    "    N = len(param_vals)\n",
    "    x2 = np.arange(N)\n",
    "    \n",
    "    training_scores = score_estimators(X_train, y_train, estimators)\n",
    "    test_scores = score_estimators(X_test, y_test, estimators)\n",
    "    val_scores = score_estimators(X_val, y_val, estimators)\n",
    "    \n",
    "    val_score_index = val_scores.index(np.max(val_scores))\n",
    "    \n",
    "    plt.plot(x2, training_scores, '-ok', color = 'g', label = 'train')\n",
    "    plt.plot(x2, val_scores, '-ok',color = 'r', label = 'val') \n",
    "    plt.plot(x2, test_scores, linestyle='dashed', color = \"k\",label = 'test' )\n",
    "    plt.plot(4,np.max(val_scores), marker = 'x', color = 'r', markersize = 16)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xticks(x2,param_vals)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.title(str(estimators[0].__class__.__name__) +' '+ 'score vs '  + str(param_name))\n",
    "    plt.text(4, 0.31,'train = ' + str(training_scores[val_score_index])[:5], color='green')\n",
    "    plt.text(4, 0.24, 'val = ' + str(val_scores[val_score_index])[:5], color='red')\n",
    "    plt.text(4, 0.17, 'test = ' + str(test_scores[val_score_index])[:5])\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_estimators(X, y, estimators):\n",
    "    \"\"\"Scores each estimator on (X, y), returning a list of scores.\"\"\"\n",
    "    scores = []\n",
    "    for estimator in estimators:\n",
    "        scores.append(estimator.score(X,y))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training various classifiers\n",
    "## Splitting the data into training, testing, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-3 lines.\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_scaled, y, train_size=0.80, test_size = 0.20, random_state=0)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, train_size=0.75, test_size = 0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-0182163c304c>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-0182163c304c>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    print(LR_scores)4023086402029753]\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "LinearRegressionEstimators = LinearRegression().fit(X_scaled, y)\n",
    "LR_train_score = LinearRegressionEstimators.score(X_train, y_train)\n",
    "LR_test_score = LinearRegressionEstimators.score(X_test, y_test)\n",
    "LR_val_score = LinearRegressionEstimators.score(X_val, y_val)\n",
    "LR_scores = [LR_train_score,LR_test_score,LR_val_score]\n",
    "print(LR_scores)\n",
    "\n",
    "1\n",
    "\n",
    "NOTE : No reasonable amount of feature selection will beat using all the feature for linear regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE : No reasonable amount of feature selection will beat using all the feature for linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMEstimator = train_estimators(X_train, y_train, sklearn.svm.SVR,\n",
    "                                   'C', [0.01, 0.1,1.0,10.0,100.0,1000.0],gamma=0.0001,max_iter=10000)\n",
    "plot_estimator_scores(SVMEstimator,'C',[0.01, 0.1,1.0,10.0,100.0,1000.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeEstimators = train_estimators(X_train, y_train, DecisionTreeRegressor,\n",
    "                                   'max_depth', [1, 5, 10,20,50,100], splitter='random', random_state=0)\n",
    "plot_estimator_scores(DecisionTreeEstimators,'max_depth',[1, 5, 10,20,50,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomTreeEstimators = train_estimators(X_train, y_train, sklearn.ensemble.RandomForestClassifier,\n",
    "                                   'max_depth', [1, 5, 10,20,50,100], random_state=0)\n",
    "plot_estimator_scores(RandomTreeEstimators,'max_depth',[1, 5, 10,20,50,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNearestEstimators = train_estimators(X_train, y_train, KNeighborsRegressor,\n",
    "                                      'weights', ['uniform','distance'],n_neighbors=2)\n",
    "plot_estimator_scores(KNearestEstimators,'weights', ['uniform','distance'])\n",
    "\n",
    "KNearestEstimators = train_estimators(X_train, y_train, KNeighborsRegressor,\n",
    "                                      'algorithm', ['auto', 'ball_tree', 'kd_tree','brute'],n_neighbors=2)\n",
    "plot_estimator_scores(KNearestEstimators,'algorithm', ['auto', 'ball_tree', 'kd_tree','brute'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostEstimators = train_estimators(X_train, y_train, AdaBoostRegressor,\n",
    "                                   'n_estimators', [10, 50, 100, 500, 1000, 5000], random_state=0)\n",
    "plot_estimator_scores(AdaBoostEstimators,'n_estimators',[10, 50, 100, 500, 1000, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianProcessRegressor()\n",
    "NaiveBayesRegressor=clf.fit(X_train, y_train)\n",
    "NB_test_scores =  NaiveBayesRegressor.score(X_test, y_test)\n",
    "NB_val_scores =  NaiveBayesRegressor.score(X_val, y_val)\n",
    "print(NB_val_scores,NB_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6151f332f26dcde9b4e9a2d5bb7904271ea54c2018786e9b563d2c471a54dc4f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
